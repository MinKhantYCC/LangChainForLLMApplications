{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"bbd49ea703614f29a1ce22fce5de616d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff9491f34b9b47f999a0c84d1e1511f9","IPY_MODEL_54692f846bf84e739542d7aa847a8399","IPY_MODEL_47e1b3fe0ade4691ac1ff56a9b6ade31"],"layout":"IPY_MODEL_d6e52ab510194809a6a17733e7df3e62"}},"ff9491f34b9b47f999a0c84d1e1511f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78ac55752d1e4d66bbf6c9215d5a7ab7","placeholder":"​","style":"IPY_MODEL_b5640879ed1b40e885f8d2bb3c48fa92","value":"Loading checkpoint shards: 100%"}},"54692f846bf84e739542d7aa847a8399":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d98f4483f164086b8fba59771ca02c0","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0a3c838dd0b48dfbd18c685e350b336","value":2}},"47e1b3fe0ade4691ac1ff56a9b6ade31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efafaadd76c9438ab33e0d891f8bda59","placeholder":"​","style":"IPY_MODEL_505041e0081748cb93a1ffaebad4d87d","value":" 2/2 [00:58&lt;00:00, 26.70s/it]"}},"d6e52ab510194809a6a17733e7df3e62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78ac55752d1e4d66bbf6c9215d5a7ab7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5640879ed1b40e885f8d2bb3c48fa92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d98f4483f164086b8fba59771ca02c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0a3c838dd0b48dfbd18c685e350b336":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"efafaadd76c9438ab33e0d891f8bda59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"505041e0081748cb93a1ffaebad4d87d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Models, Prompt, and Output Parsers\n","\n","We will practise how to create a LLM with Llama-2-7b-chat-finetune and HuggingFace pipeline. We will take reference from the LangChainForLLMApplication course of DeepLearing.ai."],"metadata":{"id":"ytYAhexaimwk"}},{"cell_type":"markdown","source":["## Setup Environment"],"metadata":{"id":"XPT7qYpkjdO2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"eReSMuULhHsf","executionInfo":{"status":"ok","timestamp":1724813416717,"user_tz":-420,"elapsed":769,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}}},"outputs":[],"source":["# %%capture\n","# !pip install langchain\n","# !pip install langchain-hub\n","# !pip install langchain-community langchain-huggingface\n","# !pip install huggingface_hub transformers\n","# !pip install sentence_transformers==2.2.2\n","# !pip install chromadb faiss accelerate\n","# !pip install -U bitsandbytes\n","# !pip install tiktoken python-dotenv"]},{"cell_type":"markdown","source":["## Import Modules"],"metadata":{"id":"VvK1IwxSjgdN"}},{"cell_type":"code","source":["# llm modules\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    pipeline\n",")\n","from transformers import GenerationConfig\n","from langchain.llms import HuggingFacePipeline\n","\n","# prompt modules\n","from langchain.prompts import PromptTemplate\n","from langchain.prompts.chat import ChatPromptTemplate\n","\n","# output parser\n","from langchain.output_parsers import ResponseSchema\n","from langchain.output_parsers import StructuredOutputParser\n","\n","# base modules\n","import os\n","import torch\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"fbH_wTOVjoBi","executionInfo":{"status":"ok","timestamp":1724813435971,"user_tz":-420,"elapsed":18423,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Create LLM from Huggingface\n","\n","We will create a LLM by using Llama2-7b-chat model from huggingface. OpenAI require API key and it is not free. Therefore, we will use our fine-tune Llama."],"metadata":{"id":"p8nCE68slUrX"}},{"cell_type":"code","source":["model_name = \"minkhantycc/Llama-2-7b-chat-finetune-quantized\"\n","device_map = {\"\": 0}"],"metadata":{"id":"_HvIyx3umQCJ","executionInfo":{"status":"ok","timestamp":1724813435972,"user_tz":-420,"elapsed":7,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# bnb config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=\"float16\",\n","    bnb_4bit_use_double_quant=False,\n",")\n","\n","\n","# base model\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    device_map=device_map\n",")\n","base_model.config.use_cache = False\n","base_model.config.pretraining_tp = 1\n","\n","# Reload tokenizer to save it\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,\n","    trust_remote_code=True\n",")\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","base_model.generation_config = GenerationConfig(\n","    max_new_tokens = 256,\n","    temperature = 0.01,\n","    repetition_penalty = 1.15,\n","    do_sample = False,\n","    eos_token_id = tokenizer.eos_token_id,\n","    pad_token_id = tokenizer.eos_token_id,\n",")\n","\n","# pipeline\n","pipe = pipeline(\n","    task=\"text-generation\",\n","    model=base_model,\n","    tokenizer=tokenizer,\n","    device_map=device_map,\n","    return_full_text=False\n",")\n","\n","# llm\n","llm = HuggingFacePipeline(pipeline=pipe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["bbd49ea703614f29a1ce22fce5de616d","ff9491f34b9b47f999a0c84d1e1511f9","54692f846bf84e739542d7aa847a8399","47e1b3fe0ade4691ac1ff56a9b6ade31","d6e52ab510194809a6a17733e7df3e62","78ac55752d1e4d66bbf6c9215d5a7ab7","b5640879ed1b40e885f8d2bb3c48fa92","0d98f4483f164086b8fba59771ca02c0","e0a3c838dd0b48dfbd18c685e350b336","efafaadd76c9438ab33e0d891f8bda59","505041e0081748cb93a1ffaebad4d87d"]},"id":"JNJTaaJAk0P6","executionInfo":{"status":"ok","timestamp":1724813497881,"user_tz":-420,"elapsed":61914,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"outputId":"6f4eaa65-1c63-4d45-85ef-b0612bab3289"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbd49ea703614f29a1ce22fce5de616d"}},"metadata":{}}]},{"cell_type":"code","source":["def get_completion(prompt, model=llm):\n","    return model.invoke(prompt)"],"metadata":{"id":"RBgUVyDkosQp","executionInfo":{"status":"ok","timestamp":1724813497881,"user_tz":-420,"elapsed":11,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["print(get_completion(\"<s>[INST] What is 1+1? [/INST]\"))"],"metadata":{"id":"SqVRKPJsxWjL","executionInfo":{"status":"ok","timestamp":1724813500840,"user_tz":-420,"elapsed":2966,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c034b958-d92c-4b70-8134-20bffb5986e3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":[" The answer to 1 + 1 is 2. \n"]}]},{"cell_type":"markdown","source":["## Prompt template"],"metadata":{"id":"vRkoumPHpBkh"}},{"cell_type":"code","source":["# create a Chat Prompt template\n","template_string = \"\"\"<s>[INST]Translate the text \\\n","that is delimited by triple backticks \\\n","into a style that is {style}. \\\n","text: ```{text}```[/INST]\n","\"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(template_string)\n","print(prompt_template)"],"metadata":{"id":"wW_v6Xyf4s7W","executionInfo":{"status":"ok","timestamp":1724813500841,"user_tz":-420,"elapsed":13,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bed608d9-9123-49d7-c78f-ab488fff541f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["input_variables=['style', 'text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], template='<s>[INST]Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```[/INST]\\n'))]\n"]}]},{"cell_type":"code","source":["# your style and email\n","custom_style = \"American English \\\n","in a calm and respectful tone\"\n","\n","custom_email = \"\"\"\n","<s>[INST]Arrr, I be fuming that me blender lid \\\n","flew off and splattered me kitchen walls \\\n","with smoothie! And to make matters worse, \\\n","the warranty don't cover the cost of \\\n","cleaning up me kitchen. I need yer help \\\n","right now, matey![/INST]\n","\"\"\"\n","\n","# add them in the prompt template\n","customer_messages = prompt_template.format_messages(\n","                    style=custom_style,\n","                    text=custom_email)\n","\n","print(customer_messages)\n","print(type(customer_messages))\n","print(type(customer_messages[0]))"],"metadata":{"id":"pS74vFZhprDz","executionInfo":{"status":"ok","timestamp":1724813500842,"user_tz":-420,"elapsed":11,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b621c367-a058-4c67-b43c-489aa9d30f80"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[HumanMessage(content=\"<s>[INST]Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone. text: ```\\n<s>[INST]Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey![/INST]\\n```[/INST]\\n\")]\n","<class 'list'>\n","<class 'langchain_core.messages.human.HumanMessage'>\n"]}]},{"cell_type":"code","source":["# get response from LLM\n","print(get_completion(customer_messages))"],"metadata":{"id":"Vz00cMfwtBYH","executionInfo":{"status":"ok","timestamp":1724813508488,"user_tz":-420,"elapsed":7653,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9befed47-ec51-427f-ecb8-210825adc028"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Oh no, it sounds like you had quite an unexpected mess on your hands there! It can be frustrating when things go awry like that, especially when they involve expensive electronics like blenders. But don't worry too much about the warranty not covering the cost of cleanup - at least you have some insurance against further damage or loss. Just take care of the situation as best you can, and try to stay level-headed through all the chaos. Good luck, matey!\n"]}]},{"cell_type":"markdown","source":["## Output Parsers"],"metadata":{"id":"W4AkwMrRtU-_"}},{"cell_type":"code","source":["customer_review = \"\"\"\\\n","This leaf blower is pretty amazing.  It has four settings:\\\n","candle blower, gentle breeze, windy city, and tornado. \\\n","It arrived in 2 days, just in time for my wife's \\\n","anniversary present. \\\n","I think my wife liked it so much she was speechless. \\\n","So far I've been the only one using it, and I've been \\\n","using it every other morning to clear the leaves on our lawn. \\\n","It's slightly more expensive than the other leaf blowers \\\n","out there, but I think it's worth it for the extra features.\n","\"\"\"\n","\n","review_template = \"\"\"<s>[INST]\\\n","For the following text, extract the following information:\n","\n","gift: Was the item purchased as a gift for someone else? \\\n","Answer True if yes, False if not or unknown.\n","\n","delivery_days: How many days did it take for the product \\\n","to arrive? If this information is not found, output -1.\n","\n","price_value: Extract any sentences about the value or price,\\\n","and output them as a comma separated Python list.\n","\n","Format the output as JSON with the following keys:\n","gift\n","delivery_days\n","price_value\n","\n","text: {text}[/INST]\n","\"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(review_template)\n","messages = prompt_template.format_messages(text=customer_review)\n","ai_response = get_completion(messages)\n","print(ai_response)\n","print(type(ai_response))"],"metadata":{"id":"SPgRPE8xtdYJ","executionInfo":{"status":"ok","timestamp":1724813512416,"user_tz":-420,"elapsed":3936,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1922b691-ada5-4159-f342-95afb555e3f7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","\"gift\": true,\n","\"delivery_days\": -1,\n","\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\", \"I think it's worth it for the extra features.\"],\n","}\n","\n","<class 'str'>\n"]}]},{"cell_type":"code","source":["gift_schema = ResponseSchema(name=\"gift\",\n","                             description=\"Was the item purchased\\\n","                             as a gift for someone else? \\\n","                             Answer True if yes,\\\n","                             False if not or unknown.\")\n","delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n","                                      description=\"How many days\\\n","                                      did it take for the product\\\n","                                      to arrive? If this \\\n","                                      information is not found,\\\n","                                      output -1.\")\n","price_value_schema = ResponseSchema(name=\"price_value\",\n","                                    description=\"Extract any\\\n","                                    sentences about the value or \\\n","                                    price, and output them as a Python list.\")\n","\n","response_schemas = [gift_schema,\n","                    delivery_days_schema,\n","                    price_value_schema]\n","\n","output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n","format_instructions = output_parser.get_format_instructions()\n","print(format_instructions)"],"metadata":{"id":"S53LKpeFuHAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724813512417,"user_tz":-420,"elapsed":15,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"outputId":"c258c9c9-7e05-440e-8ad3-d19a738dc484"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n","\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n","\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a Python list.\n","}\n","```\n"]}]},{"cell_type":"code","source":["review_template_2 = \"\"\"<s>[INST]\\\n","For the following text, extract the following information:\n","\n","gift: Was the item purchased as a gift for someone else? \\\n","Answer true if yes, false if not or unknown.\n","\n","delivery_days: How many days did it take for the product\\\n","to arrive? If this information is not found, output -1.\n","\n","price_value: Extract any sentences about the value or price,\\\n","and output them as a Python list.\n","\n","text: {text}\n","\n","{format_instructions}[/INST]\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template=review_template_2)\n","\n","messages = prompt.format_messages(text=customer_review,\n","                                format_instructions=format_instructions)\n","print(messages[0].content)"],"metadata":{"id":"WSyzvKS7uRon","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724813512417,"user_tz":-420,"elapsed":12,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"outputId":"08804f1a-f6d9-47c2-a71f-508bf615dcea"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<s>[INST]For the following text, extract the following information:\n","\n","gift: Was the item purchased as a gift for someone else? Answer true if yes, false if not or unknown.\n","\n","delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n","\n","price_value: Extract any sentences about the value or price,and output them as a Python list.\n","\n","text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in 2 days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n","\n","\n","The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n","\n","```json\n","{\n","\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n","\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n","\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a Python list.\n","}\n","```[/INST]\n","\n"]}]},{"cell_type":"code","source":["ai_response = get_completion(messages)\n","print(ai_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPRZYXYfvZNz","executionInfo":{"status":"ok","timestamp":1724813517482,"user_tz":-420,"elapsed":5072,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"outputId":"f743b285-6ed5-4d3a-fd5e-3c205b7cae44"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["```json\n","{\n","\t\"gift\": true,\n","\t\"delivery_days\": \"-1\",\n","\t\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"],\n","}\n","```\n"]}]},{"cell_type":"code","source":["output_dict = output_parser.parse(ai_response)\n","print(output_dict)\n","print(type(output_dict))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"qMII7T0Y0_jn","executionInfo":{"status":"error","timestamp":1724813517482,"user_tz":-420,"elapsed":13,"user":{"displayName":"Min Khant","userId":"11354943094952634870"}},"outputId":"24c5d830-e4fd-4547-c32b-c23a5bfb131a"},"execution_count":14,"outputs":[{"output_type":"error","ename":"OutputParserException","evalue":"Got invalid JSON object. Error: Expecting property name enclosed in double quotes: line 5 column 1 (char 180)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mjson_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string, parser)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mjson_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parse_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36m_parse_json\u001b[0;34m(json_str, parser)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# Parse the JSON string into a Python dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_partial_json\u001b[0;34m(s, strict)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# for the original string.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 5 column 1 (char 180)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-8356b2652c77>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/structured.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mexpected_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_schemas\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparse_and_check_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/utils/json.py\u001b[0m in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mjson_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_json_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOutputParserException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got invalid JSON object. Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting property name enclosed in double quotes: line 5 column 1 (char 180)"]}]}]}